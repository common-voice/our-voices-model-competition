running path.sh
running cmd.sh

===== VALIDATING DATA =====


utils/validate_data_dir.sh: file data/train/utt2spk is not sorted or has duplicates
utils/validate_data_dir.sh: file data/test/utt2spk is not sorted or has duplicates
utils/fix_data_dir.sh: file data/train/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/fix_data_dir.sh: file data/test/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 2101 utterances.
fix_data_dir.sh: old files are kept in data/test/.backup
utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 50 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 85 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 14 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 40 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

done

===== FEATURES EXTRACTION =====

steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test

===== LANGUAGE MODEL CREATION =====
==== MAKING lm.arpa ====

done

==== MAKING G.fst ====

data/local/tmp/lm.arpa

===== MONO TRAINING =====

steps/train_mono.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
2016 warnings in exp/mono/log/align.*.*.log
86 warnings in exp/mono/log/acc.*.*.log
748 warnings in exp/mono/log/update.*.log
exp/mono: nj=3 align prob=-93.69 over 2.25h [retry=0.2%, fail=0.0%] states=135 gauss=977
steps/train_mono.sh: Done training monophone system in exp/mono

===== MONO DECODING =====

WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.
-0.0677191 -0.0682811
[info]: LG not stochastic.
-0.0677191 -0.0682811
[info]: CLG not stochastic.
0.000199252 -0.135257
HCLGa is not stochastic

===== MONO ALIGNMENT =====

steps/align_si.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono exp/mono_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== TRI1 (first triphone pass) TRAINING =====

steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl --mem 2G 2000 10000 data/train data/lang_nosp exp/mono_ali_train exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali_train to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
128 warnings in exp/tri1/log/update.*.log
88 warnings in exp/tri1/log/init_model.log
1 warnings in exp/tri1/log/questions.log
34 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
23 warnings in exp/tri1/log/align.*.*.log
exp/tri1: nj=3 align prob=-90.58 over 2.25h [retry=0.1%, fail=0.0%] states=1064 gauss=10030 tree-impr=4.46
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1

===== TRI1 (first triphone pass) DECODING =====

0 -0.0682811
[info]: CLG not stochastic.
0.559478 -0.185768
HCLGa is not stochastic

===== TRI1 ALIGNMENT =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri1 exp/tri1_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== train an LDA+MLLT system =====

steps/train_lda_mllt.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali_train exp/tri2b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali_train to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
1 warnings in exp/tri2b/log/lda_acc.*.log
24 warnings in exp/tri2b/log/align.*.*.log
1 warnings in exp/tri2b/log/build_tree.log
194 warnings in exp/tri2b/log/init_model.log
434 warnings in exp/tri2b/log/update.*.log
34 warnings in exp/tri2b/log/acc.*.*.log
1 warnings in exp/tri2b/log/questions.log
exp/tri2b: nj=3 align prob=-38.25 over 2.25h [retry=0.1%, fail=0.0%] states=1328 gauss=15041 tree-impr=4.80 lda-sum=15.32 mllt:impr,logdet=0.97,1.83
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b

===== Align utts using the tri2b model =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali_train
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== Train tri3b, which is LDA+MLLT+SAT =====

steps/train_sat.sh --cmd run.pl --mem 2G 2500 15000 data/train data/lang_nosp exp/tri2b_ali_train exp/tri3b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali_train
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri2b_ali_train to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log
253 warnings in exp/tri3b/log/update.*.log
34 warnings in exp/tri3b/log/acc.*.*.log
1 warnings in exp/tri3b/log/questions.log
283 warnings in exp/tri3b/log/init_model.log
1 warnings in exp/tri3b/log/build_tree.log
26 warnings in exp/tri3b/log/align.*.*.log
5 warnings in exp/tri3b/log/fmllr.*.*.log
7 warnings in exp/tri3b/log/est_alimdl.log
steps/train_sat.sh: Likelihood evolution:
-46.7674 -46.579 -45.6833 -44.5655 -43.0507 -42.1824 -41.427 -41.0153 -40.7097 -40.215 -39.8973 -39.6788 -39.3939 -39.2254 -39.0411 -38.8639 -38.7078 -38.5651 -38.4354 -38.2451 -38.0601 -37.9103 -37.7728 -37.6563 -37.535 -37.4038 -37.2846 -37.1728 -37.0635 -36.9412 -36.8502 -36.8127 -36.7876 -36.7691 
exp/tri3b: nj=3 align prob=-40.20 over 2.25h [retry=0.1%, fail=0.0%] states=1576 gauss=15050 fmllr-impr=2.47 over 1.25h tree-impr=6.10
steps/train_sat.sh: done training SAT system in exp/tri3b

===== compute the pronunciation and silence probabilities =====

steps/get_prons.sh --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri3b
steps/get_prons.sh: exp/tri3b/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri3b/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri3b/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri3b/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri3b/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
petra 0.0235294 P E R
evit 0.025 E W I T
arc'hant 0.0555556 A R G A N T
emaoc'h 0.0555556 M A OH X
gallout 0.0555556 G A L
bezañ 0.0714286 B EY OE
unan 0.0810811 OE N
walc'h 0.0833334 W A L A X
utils/prepare_lang.sh data/local/dict <UNK> data/local/lang_tmp data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 59 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 44 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 47 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 27 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

******* format_lms **********
utils/validate_lang.pl data/lang_test_tgsmall
Checking existence of separator file
separator file data/lang_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.int corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.csl corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.int corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.int corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.csl corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.int corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.int corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.csl corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.int corresponds to data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.int corresponds to data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.int corresponds to data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.int corresponds to data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 32 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 66 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.int corresponds to data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.{txt, int} are OK

--> data/lang_test_tgsmall/L.fst is olabel sorted
--> data/lang_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_test_tgsmall/G.fst is ilabel sorted
--> data/lang_test_tgsmall/G.fst has 90082 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgsmall]
utils/validate_lang.pl data/lang_test_tgmed
Checking existence of separator file
separator file data/lang_test_tgmed/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgmed/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgmed/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.int corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.csl corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.int corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.csl corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.int corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.csl corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.int corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.csl corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.int corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.csl corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.int corresponds to data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.{txt, int} are OK

Checking data/lang_test_tgmed/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.int corresponds to data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.{txt, int} are OK

Checking data/lang_test_tgmed/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.int corresponds to data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgmed/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.int corresponds to data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgmed/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgmed/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgmed/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgmed/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgmed/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgmed/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 96 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 51 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgmed/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.int corresponds to data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.{txt, int} are OK

--> data/lang_test_tgmed/L.fst is olabel sorted
--> data/lang_test_tgmed/L_disambig.fst is olabel sorted
--> data/lang_test_tgmed/G.fst is ilabel sorted
--> data/lang_test_tgmed/G.fst has 90082 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgmed/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgmed]
******* build_const_arpa *****
****** align_fmllr ********
steps/align_fmllr.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang exp/tri3b exp/tri3b_ali_train
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train/log/analyze_alignments.log
7 warnings in exp/tri3b_ali_train/log/align_pass1.*.log
7 warnings in exp/tri3b_ali_train/log/align_pass2.*.log
1 warnings in exp/tri3b_ali_train/log/fmllr.*.log

===== STAGE 9 =====
==== Test the tri3b system with the silprobs and pron-probs ====

-0.0668344 -0.0675036
[info]: LG not stochastic.
0 -0.0675036
[info]: CLG not stochastic.
0.647196 -0.21025
HCLGa is not stochastic
****** decode_fmllr.sh ******
steps/decode_fmllr.sh --nj 3 --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 3 --cmd run.pl --mem 4G --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,10,41) and mean=17.2
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test.si/wer_10
%WER 84.29 [ 9049 / 10735, 1275 ins, 1047 del, 6727 sub ]
%SER 95.81 [ 2013 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_11
%WER 82.64 [ 8871 / 10735, 1140 ins, 1139 del, 6592 sub ]
%SER 95.67 [ 2010 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_12
%WER 81.67 [ 8767 / 10735, 1053 ins, 1240 del, 6474 sub ]
%SER 95.62 [ 2009 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_13
%WER 80.96 [ 8691 / 10735, 974 ins, 1278 del, 6439 sub ]
%SER 95.10 [ 1998 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_14
%WER 80.46 [ 8637 / 10735, 910 ins, 1350 del, 6377 sub ]
%SER 94.86 [ 1993 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_15
%WER 80.07 [ 8595 / 10735, 853 ins, 1429 del, 6313 sub ]
%SER 94.91 [ 1994 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_16
%WER 79.75 [ 8561 / 10735, 795 ins, 1487 del, 6279 sub ]
%SER 94.62 [ 1988 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_17
%WER 79.66 [ 8551 / 10735, 762 ins, 1521 del, 6268 sub ]
%SER 94.43 [ 1984 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_7
%WER 90.67 [ 9733 / 10735, 1833 ins, 803 del, 7097 sub ]
%SER 96.67 [ 2031 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_8
%WER 88.62 [ 9513 / 10735, 1640 ins, 885 del, 6988 sub ]
%SER 96.57 [ 2029 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_9
%WER 86.29 [ 9263 / 10735, 1445 ins, 951 del, 6867 sub ]
%SER 96.14 [ 2020 / 2101 ]
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,7,35) and mean=14.2
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test/wer_10
%WER 71.45 [ 7670 / 10735, 1068 ins, 958 del, 5644 sub ]
%SER 91.96 [ 1932 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_11
%WER 70.37 [ 7554 / 10735, 991 ins, 1010 del, 5553 sub ]
%SER 91.96 [ 1932 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_12
%WER 69.68 [ 7480 / 10735, 920 ins, 1064 del, 5496 sub ]
%SER 91.81 [ 1929 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_13
%WER 69.20 [ 7429 / 10735, 864 ins, 1105 del, 5460 sub ]
%SER 91.67 [ 1926 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_14
%WER 68.47 [ 7350 / 10735, 821 ins, 1135 del, 5394 sub ]
%SER 91.29 [ 1918 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_15
%WER 67.80 [ 7278 / 10735, 774 ins, 1170 del, 5334 sub ]
%SER 90.91 [ 1910 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_16
%WER 67.65 [ 7262 / 10735, 750 ins, 1212 del, 5300 sub ]
%SER 90.62 [ 1904 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_17
%WER 67.40 [ 7235 / 10735, 717 ins, 1242 del, 5276 sub ]
%SER 90.39 [ 1899 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_7
%WER 76.16 [ 8176 / 10735, 1446 ins, 777 del, 5953 sub ]
%SER 93.19 [ 1958 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_8
%WER 74.21 [ 7966 / 10735, 1280 ins, 845 del, 5841 sub ]
%SER 92.91 [ 1952 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_9
%WER 72.76 [ 7811 / 10735, 1165 ins, 903 del, 5743 sub ]
%SER 92.43 [ 1942 / 2101 ]
****** lmrescore.sh ******
steps/lmrescore.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tgmed data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tgmed_test
exp/tri3b/decode_tgmed_test/wer_10
%WER 70.64 [ 7583 / 10735, 963 ins, 1011 del, 5609 sub ]
%SER 91.86 [ 1930 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_11
%WER 69.71 [ 7483 / 10735, 908 ins, 1062 del, 5513 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_12
%WER 69.00 [ 7407 / 10735, 838 ins, 1126 del, 5443 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_13
%WER 68.50 [ 7354 / 10735, 775 ins, 1172 del, 5407 sub ]
%SER 91.53 [ 1923 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_14
%WER 67.70 [ 7268 / 10735, 731 ins, 1189 del, 5348 sub ]
%SER 91.29 [ 1918 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_15
%WER 67.37 [ 7232 / 10735, 696 ins, 1215 del, 5321 sub ]
%SER 90.96 [ 1911 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_16
%WER 67.12 [ 7205 / 10735, 672 ins, 1244 del, 5289 sub ]
%SER 90.53 [ 1902 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_17
%WER 66.94 [ 7186 / 10735, 656 ins, 1275 del, 5255 sub ]
%SER 90.34 [ 1898 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_7
%WER 74.98 [ 8049 / 10735, 1319 ins, 833 del, 5897 sub ]
%SER 92.91 [ 1952 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_8
%WER 73.41 [ 7881 / 10735, 1179 ins, 887 del, 5815 sub ]
%SER 92.67 [ 1947 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_9
%WER 71.70 [ 7697 / 10735, 1041 ins, 945 del, 5711 sub ]
%SER 92.10 [ 1935 / 2101 ]
****** lmrescore_const_arpa.sh ******
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tglarge_test
exp/tri3b/decode_tglarge_test/wer_10
%WER 70.60 [ 7579 / 10735, 963 ins, 1013 del, 5603 sub ]
%SER 91.81 [ 1929 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_11
%WER 69.70 [ 7482 / 10735, 907 ins, 1062 del, 5513 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_12
%WER 69.00 [ 7407 / 10735, 837 ins, 1129 del, 5441 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_13
%WER 68.52 [ 7356 / 10735, 776 ins, 1170 del, 5410 sub ]
%SER 91.48 [ 1922 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_14
%WER 67.69 [ 7267 / 10735, 733 ins, 1189 del, 5345 sub ]
%SER 91.24 [ 1917 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_15
%WER 67.36 [ 7231 / 10735, 696 ins, 1216 del, 5319 sub ]
%SER 90.91 [ 1910 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_16
%WER 67.12 [ 7205 / 10735, 672 ins, 1245 del, 5288 sub ]
%SER 90.48 [ 1901 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_17
%WER 66.91 [ 7183 / 10735, 656 ins, 1274 del, 5253 sub ]
%SER 90.29 [ 1897 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_7
%WER 74.93 [ 8044 / 10735, 1316 ins, 834 del, 5894 sub ]
%SER 92.91 [ 1952 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_8
%WER 73.34 [ 7873 / 10735, 1176 ins, 893 del, 5804 sub ]
%SER 92.67 [ 1947 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_9
%WER 71.67 [ 7694 / 10735, 1040 ins, 949 del, 5705 sub ]
%SER 92.10 [ 1935 / 2101 ]

===== STAGE 10 =====
==== Train a chain model ====

local/chain/run_tdnn_1j_nogpu.sh 
local/nnet3/run_ivector_common.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in data/train, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: data/train/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/get_reco2dur.sh: obtaining durations from recordings
utils/data/get_reco2dur.sh: could not get recording lengths from sphere-file headers, using wav-to-duration
utils/data/get_reco2dur.sh: computed data/train/reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed0.9
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed1.1
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed1.1
utils/data/combine_data.sh data/train_sp data/train data/train_sp_speed0.9 data/train_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh: combined segments
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train, in data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
local/nnet3/run_ivector_common.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 1 data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp
steps/compute_cmvn_stats.sh data/train_sp
Succeeded creating CMVN stats for train_sp
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
local/nnet3/run_ivector_common.sh: aligning with the perturbed low-resolution data
steps/align_fmllr.sh --nj 1 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/tri3b_ali_train_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train_sp/log/analyze_alignments.log
13 warnings in exp/tri3b_ali_train_sp/log/align_pass2.*.log
5 warnings in exp/tri3b_ali_train_sp/log/fmllr.*.log
22 warnings in exp/tri3b_ali_train_sp/log/align_pass1.*.log
local/nnet3/run_ivector_common.sh: creating high-resolution MFCC features
utils/copy_data_dir.sh: copied data from data/train_sp to data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
utils/data/perturb_data_dir_volume.sh: data/train_sp_hires/feats.scp exists; moving it to data/train_sp_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_sp_hires
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp_hires
steps/compute_cmvn_stats.sh data/train_sp_hires
Succeeded creating CMVN stats for train_sp_hires
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_hires/.backup
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/test_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 2101 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
local/nnet3/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 7908 to 1977
local/nnet3/run_ivector_common.sh: computing a PCA transform from the hires data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/nnet3/diag_ubm/train_sp_hires_subset exp/nnet3/pca_transform
Done estimating PCA transform in exp/nnet3/pca_transform
local/nnet3/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --mem 2G --nj 1 --num-frames 700000 --num-threads 8 exp/nnet3/diag_ubm/train_sp_hires_subset 512 exp/nnet3/pca_transform exp/nnet3/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3/diag_ubm/backup.KFR
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 1 machines, parallelized with 'run.pl --mem 2G'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/nnet3/run_ivector_common.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --mem 2G --nj 1 --num-threads 4 --num-processes 2 --online-cmvn-iextractor false data/train_sp_hires exp/nnet3/diag_ubm exp/nnet3/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 21 to 3963
utils/validate_data_dir.sh: Successfully validated data-directory exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2 exp/nnet3/extractor exp/nnet3/ivectors_train_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_train_sp_hires using the extractor in exp/nnet3/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 data/test_hires exp/nnet3/extractor exp/nnet3/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_test_hires using the extractor in exp/nnet3/extractor.
local/chain/run_tdnn_1j_nogpu.sh: creating lang directory data/lang_chain with chain-type topology

====== STAGE 11 ======
steps/align_fmllr_lats.sh --nj 2 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/chain/tri3b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
5 warnings in exp/chain/tri3b_train_sp_lats/log/generate_lattices.*.log
23 warnings in exp/chain/tri3b_train_sp_lats/log/align_pass1.*.log
5 warnings in exp/chain/tri3b_train_sp_lats/log/fmllr.*.log

====== STAGE 12 ======
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 3500 data/train_sp data/lang_chain exp/tri3b_ali_train_sp exp/chain/tree_sp
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri3b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri3b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree

====== STAGE 13 ======
local/chain/run_tdnn_1j_nogpu.sh: creating neural net configs using the xconfig parser

====== STAGE 14 ======
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 30 --right-context 30 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 3000000 --frames-per-eg 140,100,160 --srand 0 data/train_sp_hires exp/chain/tdnn1j_sp exp/chain/tri3b_train_sp_lats exp/chain/tdnn1j_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 7908.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn1j_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 15437 egs, with
steps/nnet3/chain/get_egs.sh:   140,100,160 labels per example, and (left,right) context = (30,30)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn1j_sp/egs
exp/chain/tdnn1j_sp: num-iters=30 nj=2..2 num-params=4.7M dim=40+100->936 combine=-0.070->-0.063 (over 2) xent:train/valid[19,29]=(-1.61,-1.38/-1.67,-1.51) logprob:train/valid[19,29]=(-0.094,-0.066/-0.114,-0.094)
steps/nnet3/chain/train.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient=0.1 --chain.l2-regularize=0.0 --chain.apply-deriv-weights=false --chain.lm-opts=--num-extra-lm-states=2000 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.srand=0 --trainer.max-param-change=2.0 --trainer.num-epochs=20 --trainer.frames-per-iter=3000000 --trainer.optimization.num-jobs-initial=2 --trainer.optimization.num-jobs-final=2 --trainer.optimization.initial-effective-lrate=0.002 --trainer.optimization.final-effective-lrate=0.0002 --trainer.num-chunk-per-minibatch=128,64 --egs.chunk-width=140,100,160 --egs.dir= --egs.opts=--frames-overlap-per-eg 0 --cleanup.remove-egs=true --use-gpu=false --reporting.email= --feat-dir=data/train_sp_hires --tree-dir=exp/chain/tree_sp --lat-dir=exp/chain/tri3b_train_sp_lats --dir=exp/chain/tdnn1j_sp
['steps/nnet3/chain/train.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient=0.1', '--chain.l2-regularize=0.0', '--chain.apply-deriv-weights=false', '--chain.lm-opts=--num-extra-lm-states=2000', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.srand=0', '--trainer.max-param-change=2.0', '--trainer.num-epochs=20', '--trainer.frames-per-iter=3000000', '--trainer.optimization.num-jobs-initial=2', '--trainer.optimization.num-jobs-final=2', '--trainer.optimization.initial-effective-lrate=0.002', '--trainer.optimization.final-effective-lrate=0.0002', '--trainer.num-chunk-per-minibatch=128,64', '--egs.chunk-width=140,100,160', '--egs.dir=', '--egs.opts=--frames-overlap-per-eg 0', '--cleanup.remove-egs=true', '--use-gpu=false', '--reporting.email=', '--feat-dir=data/train_sp_hires', '--tree-dir=exp/chain/tree_sp', '--lat-dir=exp/chain/tri3b_train_sp_lats', '--dir=exp/chain/tdnn1j_sp']

====== STAGE 15 ======
-0.0668344 -0.0675036
[info]: CLG not stochastic.
0.547698 -0.259843
HCLGa is not stochastic
0.483846 -0.181933
[info]: final HCLG is not stochastic.

====== STAGE 16 ======
steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --frames-per-chunk 140 --nj 108 --cmd run.pl --mem 4G --num-threads 4 --online-ivector-dir exp/nnet3/ivectors_test_hires exp/chain/tree_sp/graph_tgsmall data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/chain/tree_sp/graph_tgsmall exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(4,51,399) and mean=151.2
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
score best paths
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_10
%WER 52.69 [ 5656 / 10735, 535 ins, 909 del, 4212 sub ]
%SER 83.20 [ 1748 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_11
%WER 52.57 [ 5643 / 10735, 489 ins, 953 del, 4201 sub ]
%SER 83.06 [ 1745 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_12
%WER 52.87 [ 5676 / 10735, 464 ins, 996 del, 4216 sub ]
%SER 83.06 [ 1745 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_13
%WER 53.59 [ 5753 / 10735, 439 ins, 1056 del, 4258 sub ]
%SER 83.34 [ 1751 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_14
%WER 54.27 [ 5826 / 10735, 417 ins, 1122 del, 4287 sub ]
%SER 83.82 [ 1761 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_15
%WER 54.95 [ 5899 / 10735, 399 ins, 1177 del, 4323 sub ]
%SER 84.15 [ 1768 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_16
%WER 55.65 [ 5974 / 10735, 395 ins, 1213 del, 4366 sub ]
%SER 84.58 [ 1777 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_17
%WER 56.14 [ 6027 / 10735, 376 ins, 1255 del, 4396 sub ]
%SER 85.05 [ 1787 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_7
%WER 55.52 [ 5960 / 10735, 763 ins, 777 del, 4420 sub ]
%SER 83.86 [ 1762 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_8
%WER 53.84 [ 5780 / 10735, 655 ins, 834 del, 4291 sub ]
%SER 83.29 [ 1750 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_9
%WER 52.87 [ 5676 / 10735, 586 ins, 867 del, 4223 sub ]
%SER 82.87 [ 1741 / 2101 ]
score confidence and timing with sclite
Decoding done.
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test exp/chain/tdnn1j_sp/decode_tglarge_test
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_10
%WER 52.73 [ 5661 / 10735, 492 ins, 943 del, 4226 sub ]
%SER 83.01 [ 1744 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_11
%WER 52.64 [ 5651 / 10735, 450 ins, 1001 del, 4200 sub ]
%SER 82.96 [ 1743 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_12
%WER 52.83 [ 5671 / 10735, 398 ins, 1046 del, 4227 sub ]
%SER 83.29 [ 1750 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_13
%WER 53.42 [ 5735 / 10735, 391 ins, 1116 del, 4228 sub ]
%SER 83.39 [ 1752 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_14
%WER 53.73 [ 5768 / 10735, 354 ins, 1182 del, 4232 sub ]
%SER 83.67 [ 1758 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_15
%WER 54.51 [ 5852 / 10735, 353 ins, 1230 del, 4269 sub ]
%SER 83.96 [ 1764 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_16
%WER 55.25 [ 5931 / 10735, 343 ins, 1279 del, 4309 sub ]
%SER 84.44 [ 1774 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_17
%WER 55.89 [ 6000 / 10735, 342 ins, 1311 del, 4347 sub ]
%SER 85.01 [ 1786 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_7
%WER 55.32 [ 5939 / 10735, 714 ins, 802 del, 4423 sub ]
%SER 83.91 [ 1763 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_8
%WER 53.69 [ 5764 / 10735, 615 ins, 871 del, 4278 sub ]
%SER 83.29 [ 1750 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_9
%WER 53.18 [ 5709 / 10735, 545 ins, 910 del, 4254 sub ]
%SER 82.96 [ 1743 / 2101 ]

====== STAGE 17 ======
steps/online/nnet3/prepare_online_decoding.sh --mfcc-config conf/mfcc_hires.conf data/lang_chain exp/nnet3/extractor exp/chain/tdnn1j_sp exp/chain/tdnn1j_sp_online
steps/online/nnet3/prepare_online_decoding.sh: preparing configuration files in /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf
steps/online/nnet3/prepare_online_decoding.sh: created config file /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf/online.conf
steps/online/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 108 --cmd run.pl --mem 4G exp/chain/tree_sp/graph_tgsmall data/test exp/chain/tdnn1j_sp_online/decode_tgsmall_test
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_10
%WER 52.46 [ 5632 / 10735, 533 ins, 906 del, 4193 sub ]
%SER 82.82 [ 1740 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_11
%WER 52.43 [ 5628 / 10735, 482 ins, 951 del, 4195 sub ]
%SER 83.15 [ 1747 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_12
%WER 52.87 [ 5676 / 10735, 473 ins, 993 del, 4210 sub ]
%SER 83.10 [ 1746 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_13
%WER 53.54 [ 5748 / 10735, 438 ins, 1053 del, 4257 sub ]
%SER 83.25 [ 1749 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_14
%WER 54.11 [ 5809 / 10735, 415 ins, 1109 del, 4285 sub ]
%SER 83.58 [ 1756 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_15
%WER 54.79 [ 5882 / 10735, 395 ins, 1182 del, 4305 sub ]
%SER 84.06 [ 1766 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_16
%WER 55.32 [ 5939 / 10735, 393 ins, 1200 del, 4346 sub ]
%SER 84.63 [ 1778 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_17
%WER 55.83 [ 5993 / 10735, 384 ins, 1229 del, 4380 sub ]
%SER 85.01 [ 1786 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_7
%WER 55.16 [ 5921 / 10735, 749 ins, 785 del, 4387 sub ]
%SER 83.82 [ 1761 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_8
%WER 53.85 [ 5781 / 10735, 655 ins, 846 del, 4280 sub ]
%SER 83.15 [ 1747 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_9
%WER 52.94 [ 5683 / 10735, 590 ins, 872 del, 4221 sub ]
%SER 82.72 [ 1738 / 2101 ]
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp_online/decode_tgsmall_test exp/chain/tdnn1j_sp_online/decode_tglarge_test
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_10
%WER 52.66 [ 5653 / 10735, 491 ins, 951 del, 4211 sub ]
%SER 82.82 [ 1740 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_11
%WER 52.41 [ 5626 / 10735, 446 ins, 992 del, 4188 sub ]
%SER 83.15 [ 1747 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_12
%WER 52.81 [ 5669 / 10735, 414 ins, 1041 del, 4214 sub ]
%SER 83.29 [ 1750 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_13
%WER 53.34 [ 5726 / 10735, 384 ins, 1106 del, 4236 sub ]
%SER 83.29 [ 1750 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_14
%WER 53.66 [ 5760 / 10735, 364 ins, 1169 del, 4227 sub ]
%SER 83.67 [ 1758 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_15
%WER 54.38 [ 5838 / 10735, 356 ins, 1230 del, 4252 sub ]
%SER 83.86 [ 1762 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_16
%WER 55.09 [ 5914 / 10735, 348 ins, 1275 del, 4291 sub ]
%SER 84.48 [ 1775 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_17
%WER 55.47 [ 5955 / 10735, 342 ins, 1286 del, 4327 sub ]
%SER 84.96 [ 1785 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_7
%WER 54.99 [ 5903 / 10735, 709 ins, 813 del, 4381 sub ]
%SER 84.01 [ 1765 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_8
%WER 53.70 [ 5765 / 10735, 615 ins, 872 del, 4278 sub ]
%SER 83.10 [ 1746 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_9
%WER 53.07 [ 5697 / 10735, 539 ins, 915 del, 4243 sub ]
%SER 82.72 [ 1738 / 2101 ]

===== run.sh script is finished =====

