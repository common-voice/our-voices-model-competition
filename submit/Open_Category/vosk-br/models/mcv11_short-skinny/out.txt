running path.sh
running cmd.sh

===== VALIDATING DATA =====


utils/validate_data_dir.sh: file data/train/utt2spk is not sorted or has duplicates
utils/validate_data_dir.sh: file data/test/utt2spk is not sorted or has duplicates
utils/fix_data_dir.sh: file data/train/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/fix_data_dir.sh: file data/test/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 2101 utterances.
fix_data_dir.sh: old files are kept in data/test/.backup
utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 54 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 90 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 44 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 84 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

done

===== FEATURES EXTRACTION =====

steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test

===== LANGUAGE MODEL CREATION =====
==== MAKING lm.arpa ====

done

==== MAKING G.fst ====

data/local/tmp/lm.arpa

===== MONO TRAINING =====

steps/train_mono.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
2016 warnings in exp/mono/log/align.*.*.log
86 warnings in exp/mono/log/acc.*.*.log
748 warnings in exp/mono/log/update.*.log
exp/mono: nj=3 align prob=-93.69 over 2.25h [retry=0.2%, fail=0.0%] states=135 gauss=977
steps/train_mono.sh: Done training monophone system in exp/mono

===== MONO DECODING =====

WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.
-0.0517483 -0.0524622
[info]: LG not stochastic.
-0.0517483 -0.0524622
[info]: CLG not stochastic.
0.000199252 -0.101348
HCLGa is not stochastic

===== MONO ALIGNMENT =====

steps/align_si.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono exp/mono_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== TRI1 (first triphone pass) TRAINING =====

steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl --mem 2G 2000 10000 data/train data/lang_nosp exp/mono_ali_train exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali_train to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
1 warnings in exp/tri1/log/build_tree.log
23 warnings in exp/tri1/log/align.*.*.log
1 warnings in exp/tri1/log/questions.log
88 warnings in exp/tri1/log/init_model.log
128 warnings in exp/tri1/log/update.*.log
34 warnings in exp/tri1/log/acc.*.*.log
exp/tri1: nj=3 align prob=-90.58 over 2.25h [retry=0.1%, fail=0.0%] states=1064 gauss=10030 tree-impr=4.46
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1

===== TRI1 (first triphone pass) DECODING =====

0 -0.0524622
[info]: CLG not stochastic.
0.583665 -0.144308
HCLGa is not stochastic

===== TRI1 ALIGNMENT =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri1 exp/tri1_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== train an LDA+MLLT system =====

steps/train_lda_mllt.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali_train exp/tri2b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali_train to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
434 warnings in exp/tri2b/log/update.*.log
1 warnings in exp/tri2b/log/questions.log
34 warnings in exp/tri2b/log/acc.*.*.log
1 warnings in exp/tri2b/log/lda_acc.*.log
194 warnings in exp/tri2b/log/init_model.log
24 warnings in exp/tri2b/log/align.*.*.log
1 warnings in exp/tri2b/log/build_tree.log
exp/tri2b: nj=3 align prob=-38.25 over 2.25h [retry=0.1%, fail=0.0%] states=1328 gauss=15041 tree-impr=4.80 lda-sum=15.32 mllt:impr,logdet=0.97,1.83
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b

===== Align utts using the tri2b model =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali_train
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== Train tri3b, which is LDA+MLLT+SAT =====

steps/train_sat.sh --cmd run.pl --mem 2G 2500 15000 data/train data/lang_nosp exp/tri2b_ali_train exp/tri3b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali_train
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri2b_ali_train to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log
1 warnings in exp/tri3b/log/questions.log
34 warnings in exp/tri3b/log/acc.*.*.log
283 warnings in exp/tri3b/log/init_model.log
26 warnings in exp/tri3b/log/align.*.*.log
253 warnings in exp/tri3b/log/update.*.log
5 warnings in exp/tri3b/log/fmllr.*.*.log
1 warnings in exp/tri3b/log/build_tree.log
7 warnings in exp/tri3b/log/est_alimdl.log
steps/train_sat.sh: Likelihood evolution:
-46.7674 -46.579 -45.6833 -44.5655 -43.0507 -42.1824 -41.427 -41.0153 -40.7097 -40.215 -39.8973 -39.6788 -39.3939 -39.2254 -39.0411 -38.8639 -38.7078 -38.5651 -38.4354 -38.2451 -38.0601 -37.9103 -37.7728 -37.6563 -37.535 -37.4038 -37.2846 -37.1728 -37.0635 -36.9412 -36.8502 -36.8127 -36.7876 -36.7691 
exp/tri3b: nj=3 align prob=-40.20 over 2.25h [retry=0.1%, fail=0.0%] states=1576 gauss=15050 fmllr-impr=2.47 over 1.25h tree-impr=6.10
steps/train_sat.sh: done training SAT system in exp/tri3b

===== compute the pronunciation and silence probabilities =====

steps/get_prons.sh --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri3b
steps/get_prons.sh: exp/tri3b/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri3b/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri3b/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri3b/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri3b/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
petra 0.0235294 P E R
evit 0.025 E W I T
arc'hant 0.0555556 A R G A N T
emaoc'h 0.0555556 M A OH X
gallout 0.0555556 G A L
beza√± 0.0714286 B EY OE
unan 0.0810811 OE N
walc'h 0.0833334 W A L A X
utils/prepare_lang.sh data/local/dict <UNK> data/local/lang_tmp data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 42 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 100 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 8 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 65 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

******* format_lms **********
utils/validate_lang.pl data/lang_test_tgsmall
Checking existence of separator file
separator file data/lang_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.int corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.csl corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.int corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.int corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.csl corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.int corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.int corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.csl corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.int corresponds to data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.int corresponds to data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.int corresponds to data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.int corresponds to data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 72 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 98 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.int corresponds to data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.{txt, int} are OK

--> data/lang_test_tgsmall/L.fst is olabel sorted
--> data/lang_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_test_tgsmall/G.fst is ilabel sorted
--> data/lang_test_tgsmall/G.fst has 3399 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgsmall]
utils/validate_lang.pl data/lang_test_tgmed
Checking existence of separator file
separator file data/lang_test_tgmed/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgmed/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgmed/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.int corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.csl corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.int corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.csl corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.int corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.csl corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.int corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.csl corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.int corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.csl corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.int corresponds to data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.{txt, int} are OK

Checking data/lang_test_tgmed/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.int corresponds to data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.{txt, int} are OK

Checking data/lang_test_tgmed/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.int corresponds to data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgmed/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.int corresponds to data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgmed/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgmed/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgmed/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgmed/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgmed/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgmed/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 36 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 46 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgmed/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.int corresponds to data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.{txt, int} are OK

--> data/lang_test_tgmed/L.fst is olabel sorted
--> data/lang_test_tgmed/L_disambig.fst is olabel sorted
--> data/lang_test_tgmed/G.fst is ilabel sorted
--> data/lang_test_tgmed/G.fst has 3399 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgmed/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgmed]
******* build_const_arpa *****
****** align_fmllr ********
steps/align_fmllr.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang exp/tri3b exp/tri3b_ali_train
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train/log/analyze_alignments.log
1 warnings in exp/tri3b_ali_train/log/fmllr.*.log
7 warnings in exp/tri3b_ali_train/log/align_pass1.*.log
7 warnings in exp/tri3b_ali_train/log/align_pass2.*.log

===== STAGE 9 =====
==== Test the tri3b system with the silprobs and pron-probs ====

-0.0827318 -0.0835789
[info]: LG not stochastic.
0 -0.0835789
[info]: CLG not stochastic.
0.598171 -0.2529
HCLGa is not stochastic
****** decode_fmllr.sh ******
steps/decode_fmllr.sh --nj 3 --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 3 --cmd run.pl --mem 4G --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,10,43) and mean=17.5
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test.si/wer_10
%WER 85.78 [ 9208 / 10735, 1632 ins, 899 del, 6677 sub ]
%SER 96.00 [ 2017 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_11
%WER 84.09 [ 9027 / 10735, 1454 ins, 991 del, 6582 sub ]
%SER 95.86 [ 2014 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_12
%WER 82.97 [ 8907 / 10735, 1331 ins, 1098 del, 6478 sub ]
%SER 95.67 [ 2010 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_13
%WER 81.90 [ 8792 / 10735, 1214 ins, 1168 del, 6410 sub ]
%SER 95.48 [ 2006 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_14
%WER 80.93 [ 8688 / 10735, 1098 ins, 1247 del, 6343 sub ]
%SER 95.43 [ 2005 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_15
%WER 80.14 [ 8603 / 10735, 1005 ins, 1312 del, 6286 sub ]
%SER 95.34 [ 2003 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_16
%WER 79.83 [ 8570 / 10735, 946 ins, 1397 del, 6227 sub ]
%SER 95.15 [ 1999 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_17
%WER 79.52 [ 8537 / 10735, 895 ins, 1463 del, 6179 sub ]
%SER 95.15 [ 1999 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_7
%WER 94.21 [ 10113 / 10735, 2374 ins, 600 del, 7139 sub ]
%SER 96.86 [ 2035 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_8
%WER 91.01 [ 9770 / 10735, 2108 ins, 688 del, 6974 sub ]
%SER 96.53 [ 2028 / 2101 ]
exp/tri3b/decode_tgsmall_test.si/wer_9
%WER 88.03 [ 9450 / 10735, 1852 ins, 790 del, 6808 sub ]
%SER 96.24 [ 2022 / 2101 ]
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,6,30) and mean=12.0
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test/wer_10
%WER 74.18 [ 7963 / 10735, 1493 ins, 730 del, 5740 sub ]
%SER 92.57 [ 1945 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_11
%WER 73.15 [ 7853 / 10735, 1387 ins, 784 del, 5682 sub ]
%SER 92.38 [ 1941 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_12
%WER 71.94 [ 7723 / 10735, 1276 ins, 827 del, 5620 sub ]
%SER 92.24 [ 1938 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_13
%WER 70.82 [ 7603 / 10735, 1179 ins, 867 del, 5557 sub ]
%SER 91.86 [ 1930 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_14
%WER 70.30 [ 7547 / 10735, 1113 ins, 925 del, 5509 sub ]
%SER 91.81 [ 1929 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_15
%WER 69.83 [ 7496 / 10735, 1049 ins, 999 del, 5448 sub ]
%SER 91.62 [ 1925 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_16
%WER 69.22 [ 7431 / 10735, 990 ins, 1035 del, 5406 sub ]
%SER 91.58 [ 1924 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_17
%WER 69.05 [ 7413 / 10735, 959 ins, 1073 del, 5381 sub ]
%SER 91.58 [ 1924 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_7
%WER 79.50 [ 8534 / 10735, 1977 ins, 589 del, 5968 sub ]
%SER 93.57 [ 1966 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_8
%WER 77.38 [ 8307 / 10735, 1802 ins, 622 del, 5883 sub ]
%SER 93.19 [ 1958 / 2101 ]
exp/tri3b/decode_tgsmall_test/wer_9
%WER 75.94 [ 8152 / 10735, 1652 ins, 666 del, 5834 sub ]
%SER 92.96 [ 1953 / 2101 ]
****** lmrescore.sh ******
steps/lmrescore.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tgmed data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tgmed_test
exp/tri3b/decode_tgmed_test/wer_10
%WER 74.08 [ 7953 / 10735, 1484 ins, 731 del, 5738 sub ]
%SER 92.62 [ 1946 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_11
%WER 73.16 [ 7854 / 10735, 1382 ins, 790 del, 5682 sub ]
%SER 92.48 [ 1943 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_12
%WER 71.98 [ 7727 / 10735, 1267 ins, 836 del, 5624 sub ]
%SER 92.24 [ 1938 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_13
%WER 70.93 [ 7614 / 10735, 1172 ins, 875 del, 5567 sub ]
%SER 91.86 [ 1930 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_14
%WER 70.39 [ 7556 / 10735, 1098 ins, 939 del, 5519 sub ]
%SER 91.86 [ 1930 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_15
%WER 69.96 [ 7510 / 10735, 1040 ins, 1009 del, 5461 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_16
%WER 69.28 [ 7437 / 10735, 979 ins, 1053 del, 5405 sub ]
%SER 91.58 [ 1924 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_17
%WER 69.11 [ 7419 / 10735, 953 ins, 1090 del, 5376 sub ]
%SER 91.67 [ 1926 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_7
%WER 79.40 [ 8524 / 10735, 1962 ins, 591 del, 5971 sub ]
%SER 93.57 [ 1966 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_8
%WER 77.37 [ 8306 / 10735, 1794 ins, 624 del, 5888 sub ]
%SER 93.19 [ 1958 / 2101 ]
exp/tri3b/decode_tgmed_test/wer_9
%WER 75.93 [ 8151 / 10735, 1644 ins, 671 del, 5836 sub ]
%SER 92.96 [ 1953 / 2101 ]
****** lmrescore_const_arpa.sh ******
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tglarge_test
exp/tri3b/decode_tglarge_test/wer_10
%WER 74.05 [ 7949 / 10735, 1482 ins, 729 del, 5738 sub ]
%SER 92.62 [ 1946 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_11
%WER 73.11 [ 7848 / 10735, 1380 ins, 788 del, 5680 sub ]
%SER 92.48 [ 1943 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_12
%WER 71.95 [ 7724 / 10735, 1266 ins, 834 del, 5624 sub ]
%SER 92.29 [ 1939 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_13
%WER 70.87 [ 7608 / 10735, 1169 ins, 874 del, 5565 sub ]
%SER 91.91 [ 1931 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_14
%WER 70.36 [ 7553 / 10735, 1100 ins, 938 del, 5515 sub ]
%SER 91.91 [ 1931 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_15
%WER 69.91 [ 7505 / 10735, 1042 ins, 1005 del, 5458 sub ]
%SER 91.72 [ 1927 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_16
%WER 69.24 [ 7433 / 10735, 980 ins, 1048 del, 5405 sub ]
%SER 91.58 [ 1924 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_17
%WER 69.09 [ 7417 / 10735, 957 ins, 1082 del, 5378 sub ]
%SER 91.67 [ 1926 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_7
%WER 79.38 [ 8521 / 10735, 1961 ins, 591 del, 5969 sub ]
%SER 93.57 [ 1966 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_8
%WER 77.35 [ 8304 / 10735, 1796 ins, 623 del, 5885 sub ]
%SER 93.19 [ 1958 / 2101 ]
exp/tri3b/decode_tglarge_test/wer_9
%WER 75.90 [ 8148 / 10735, 1645 ins, 670 del, 5833 sub ]
%SER 92.96 [ 1953 / 2101 ]

===== STAGE 10 =====
==== Train a chain model ====

local/chain/run_tdnn_1j_nogpu_short-skinny.sh 
local/nnet3/run_ivector_common.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in data/train, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: data/train/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/get_reco2dur.sh: obtaining durations from recordings
utils/data/get_reco2dur.sh: could not get recording lengths from sphere-file headers, using wav-to-duration
utils/data/get_reco2dur.sh: computed data/train/reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed0.9
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed1.1
fix_data_dir.sh: kept all 2636 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed1.1
utils/data/combine_data.sh data/train_sp data/train data/train_sp_speed0.9 data/train_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh: combined segments
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train, in data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
local/nnet3/run_ivector_common.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 1 data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp
steps/compute_cmvn_stats.sh data/train_sp
Succeeded creating CMVN stats for train_sp
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
local/nnet3/run_ivector_common.sh: aligning with the perturbed low-resolution data
steps/align_fmllr.sh --nj 1 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/tri3b_ali_train_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train_sp/log/analyze_alignments.log
22 warnings in exp/tri3b_ali_train_sp/log/align_pass1.*.log
6 warnings in exp/tri3b_ali_train_sp/log/fmllr.*.log
14 warnings in exp/tri3b_ali_train_sp/log/align_pass2.*.log
local/nnet3/run_ivector_common.sh: creating high-resolution MFCC features
utils/copy_data_dir.sh: copied data from data/train_sp to data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
utils/data/perturb_data_dir_volume.sh: data/train_sp_hires/feats.scp exists; moving it to data/train_sp_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_sp_hires
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp_hires
steps/compute_cmvn_stats.sh data/train_sp_hires
Succeeded creating CMVN stats for train_sp_hires
fix_data_dir.sh: kept all 7908 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_hires/.backup
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/test_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 2101 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
local/nnet3/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 7908 to 1977
local/nnet3/run_ivector_common.sh: computing a PCA transform from the hires data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/nnet3/diag_ubm/train_sp_hires_subset exp/nnet3/pca_transform
Done estimating PCA transform in exp/nnet3/pca_transform
local/nnet3/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --mem 2G --nj 1 --num-frames 700000 --num-threads 8 exp/nnet3/diag_ubm/train_sp_hires_subset 512 exp/nnet3/pca_transform exp/nnet3/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3/diag_ubm/backup.tO1
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 1 machines, parallelized with 'run.pl --mem 2G'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/nnet3/run_ivector_common.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --mem 2G --nj 1 --num-threads 4 --num-processes 2 --online-cmvn-iextractor false data/train_sp_hires exp/nnet3/diag_ubm exp/nnet3/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 21 to 3963
utils/validate_data_dir.sh: Successfully validated data-directory exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2 exp/nnet3/extractor exp/nnet3/ivectors_train_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_train_sp_hires using the extractor in exp/nnet3/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 data/test_hires exp/nnet3/extractor exp/nnet3/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_test_hires using the extractor in exp/nnet3/extractor.
local/chain/run_tdnn_1j_nogpu_short-skinny.sh: creating lang directory data/lang_chain with chain-type topology

====== STAGE 11 ======
steps/align_fmllr_lats.sh --nj 2 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/chain/tri3b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
5 warnings in exp/chain/tri3b_train_sp_lats/log/generate_lattices.*.log
23 warnings in exp/chain/tri3b_train_sp_lats/log/align_pass1.*.log
6 warnings in exp/chain/tri3b_train_sp_lats/log/fmllr.*.log

====== STAGE 12 ======
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 3500 data/train_sp data/lang_chain exp/tri3b_ali_train_sp exp/chain/tree_sp
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri3b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri3b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree

====== STAGE 13 ======
local/chain/run_tdnn_1j_nogpu_short-skinny.sh: creating neural net configs using the xconfig parser

====== STAGE 14 ======
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 24 --right-context 24 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 3000000 --frames-per-eg 140,100,160 --srand 0 data/train_sp_hires exp/chain/tdnn1j_sp exp/chain/tri3b_train_sp_lats exp/chain/tdnn1j_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 7908.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn1j_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 1 archives, each with 15437 egs, with
steps/nnet3/chain/get_egs.sh:   140,100,160 labels per example, and (left,right) context = (24,24)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn1j_sp/egs
exp/chain/tdnn1j_sp: num-iters=30 nj=2..2 num-params=2.8M dim=40+100->936 combine=-0.071->-0.067 (over 3) xent:train/valid[19,29]=(-1.68,-1.47/-1.77,-1.57) logprob:train/valid[19,29]=(-0.098,-0.073/-0.119,-0.097)
steps/nnet3/chain/train.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient=0.1 --chain.l2-regularize=0.0 --chain.apply-deriv-weights=false --chain.lm-opts=--num-extra-lm-states=2000 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.srand=0 --trainer.max-param-change=2.0 --trainer.num-epochs=20 --trainer.frames-per-iter=3000000 --trainer.optimization.num-jobs-initial=2 --trainer.optimization.num-jobs-final=2 --trainer.optimization.initial-effective-lrate=0.002 --trainer.optimization.final-effective-lrate=0.0002 --trainer.num-chunk-per-minibatch=128,64 --egs.chunk-width=140,100,160 --egs.dir= --egs.opts=--frames-overlap-per-eg 0 --cleanup.remove-egs=true --use-gpu=false --reporting.email= --feat-dir=data/train_sp_hires --tree-dir=exp/chain/tree_sp --lat-dir=exp/chain/tri3b_train_sp_lats --dir=exp/chain/tdnn1j_sp
['steps/nnet3/chain/train.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient=0.1', '--chain.l2-regularize=0.0', '--chain.apply-deriv-weights=false', '--chain.lm-opts=--num-extra-lm-states=2000', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.srand=0', '--trainer.max-param-change=2.0', '--trainer.num-epochs=20', '--trainer.frames-per-iter=3000000', '--trainer.optimization.num-jobs-initial=2', '--trainer.optimization.num-jobs-final=2', '--trainer.optimization.initial-effective-lrate=0.002', '--trainer.optimization.final-effective-lrate=0.0002', '--trainer.num-chunk-per-minibatch=128,64', '--egs.chunk-width=140,100,160', '--egs.dir=', '--egs.opts=--frames-overlap-per-eg 0', '--cleanup.remove-egs=true', '--use-gpu=false', '--reporting.email=', '--feat-dir=data/train_sp_hires', '--tree-dir=exp/chain/tree_sp', '--lat-dir=exp/chain/tri3b_train_sp_lats', '--dir=exp/chain/tdnn1j_sp']

====== STAGE 15 ======
-0.0827318 -0.0835789
[info]: CLG not stochastic.
0.495092 -0.274684
HCLGa is not stochastic
0.362384 -0.185247
[info]: final HCLG is not stochastic.

====== STAGE 16 ======
steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --frames-per-chunk 140 --nj 108 --cmd run.pl --mem 4G --num-threads 4 --online-ivector-dir exp/nnet3/ivectors_test_hires exp/chain/tree_sp/graph_tgsmall data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/chain/tree_sp/graph_tgsmall exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,38,325) and mean=128.3
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
score best paths
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_10
%WER 55.36 [ 5943 / 10735, 775 ins, 728 del, 4440 sub ]
%SER 83.72 [ 1759 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_11
%WER 55.33 [ 5940 / 10735, 712 ins, 797 del, 4431 sub ]
%SER 84.15 [ 1768 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_12
%WER 55.42 [ 5949 / 10735, 652 ins, 859 del, 4438 sub ]
%SER 84.39 [ 1773 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_13
%WER 55.53 [ 5961 / 10735, 602 ins, 929 del, 4430 sub ]
%SER 84.82 [ 1782 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_14
%WER 55.76 [ 5986 / 10735, 556 ins, 981 del, 4449 sub ]
%SER 85.05 [ 1787 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_15
%WER 56.04 [ 6016 / 10735, 507 ins, 1034 del, 4475 sub ]
%SER 85.53 [ 1797 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_16
%WER 56.53 [ 6069 / 10735, 481 ins, 1099 del, 4489 sub ]
%SER 86.05 [ 1808 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_17
%WER 56.86 [ 6104 / 10735, 462 ins, 1167 del, 4475 sub ]
%SER 86.39 [ 1815 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_7
%WER 58.87 [ 6320 / 10735, 1123 ins, 565 del, 4632 sub ]
%SER 84.96 [ 1785 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_8
%WER 57.22 [ 6143 / 10735, 984 ins, 637 del, 4522 sub ]
%SER 84.39 [ 1773 / 2101 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_9
%WER 56.20 [ 6033 / 10735, 871 ins, 676 del, 4486 sub ]
%SER 84.39 [ 1773 / 2101 ]
score confidence and timing with sclite
Decoding done.
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test exp/chain/tdnn1j_sp/decode_tglarge_test
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_10
%WER 55.41 [ 5948 / 10735, 765 ins, 740 del, 4443 sub ]
%SER 84.06 [ 1766 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_11
%WER 55.29 [ 5935 / 10735, 701 ins, 812 del, 4422 sub ]
%SER 84.29 [ 1771 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_12
%WER 55.33 [ 5940 / 10735, 642 ins, 872 del, 4426 sub ]
%SER 84.48 [ 1775 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_13
%WER 55.51 [ 5959 / 10735, 595 ins, 940 del, 4424 sub ]
%SER 84.86 [ 1783 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_14
%WER 55.82 [ 5992 / 10735, 551 ins, 1002 del, 4439 sub ]
%SER 85.20 [ 1790 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_15
%WER 56.11 [ 6023 / 10735, 503 ins, 1056 del, 4464 sub ]
%SER 85.67 [ 1800 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_16
%WER 56.61 [ 6077 / 10735, 474 ins, 1124 del, 4479 sub ]
%SER 86.24 [ 1812 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_17
%WER 56.90 [ 6108 / 10735, 452 ins, 1192 del, 4464 sub ]
%SER 86.58 [ 1819 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_7
%WER 58.78 [ 6310 / 10735, 1112 ins, 572 del, 4626 sub ]
%SER 84.96 [ 1785 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_8
%WER 57.14 [ 6134 / 10735, 979 ins, 638 del, 4517 sub ]
%SER 84.29 [ 1771 / 2101 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_9
%WER 56.15 [ 6028 / 10735, 861 ins, 685 del, 4482 sub ]
%SER 84.53 [ 1776 / 2101 ]

====== STAGE 17 ======
steps/online/nnet3/prepare_online_decoding.sh --mfcc-config conf/mfcc_hires.conf data/lang_chain exp/nnet3/extractor exp/chain/tdnn1j_sp exp/chain/tdnn1j_sp_online
steps/online/nnet3/prepare_online_decoding.sh: preparing configuration files in /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf
steps/online/nnet3/prepare_online_decoding.sh: created config file /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf/online.conf
steps/online/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 108 --cmd run.pl --mem 4G exp/chain/tree_sp/graph_tgsmall data/test exp/chain/tdnn1j_sp_online/decode_tgsmall_test
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_10
%WER 55.31 [ 5937 / 10735, 771 ins, 737 del, 4429 sub ]
%SER 83.63 [ 1757 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_11
%WER 55.03 [ 5907 / 10735, 697 ins, 793 del, 4417 sub ]
%SER 83.96 [ 1764 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_12
%WER 55.22 [ 5928 / 10735, 652 ins, 870 del, 4406 sub ]
%SER 84.01 [ 1765 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_13
%WER 55.51 [ 5959 / 10735, 607 ins, 935 del, 4417 sub ]
%SER 84.77 [ 1781 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_14
%WER 55.71 [ 5980 / 10735, 573 ins, 987 del, 4420 sub ]
%SER 85.10 [ 1788 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_15
%WER 55.96 [ 6007 / 10735, 521 ins, 1034 del, 4452 sub ]
%SER 85.58 [ 1798 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_16
%WER 56.57 [ 6073 / 10735, 501 ins, 1085 del, 4487 sub ]
%SER 86.10 [ 1809 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_17
%WER 56.79 [ 6096 / 10735, 483 ins, 1135 del, 4478 sub ]
%SER 86.48 [ 1817 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_7
%WER 58.84 [ 6317 / 10735, 1128 ins, 553 del, 4636 sub ]
%SER 84.86 [ 1783 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_8
%WER 57.21 [ 6142 / 10735, 995 ins, 634 del, 4513 sub ]
%SER 84.39 [ 1773 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_9
%WER 56.04 [ 6016 / 10735, 869 ins, 676 del, 4471 sub ]
%SER 84.10 [ 1767 / 2101 ]
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp_online/decode_tgsmall_test exp/chain/tdnn1j_sp_online/decode_tglarge_test
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_10
%WER 55.32 [ 5939 / 10735, 764 ins, 748 del, 4427 sub ]
%SER 83.96 [ 1764 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_11
%WER 55.08 [ 5913 / 10735, 688 ins, 807 del, 4418 sub ]
%SER 84.06 [ 1766 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_12
%WER 55.22 [ 5928 / 10735, 642 ins, 882 del, 4404 sub ]
%SER 84.29 [ 1771 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_13
%WER 55.52 [ 5960 / 10735, 594 ins, 942 del, 4424 sub ]
%SER 84.77 [ 1781 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_14
%WER 55.78 [ 5988 / 10735, 568 ins, 1002 del, 4418 sub ]
%SER 85.01 [ 1786 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_15
%WER 56.22 [ 6035 / 10735, 521 ins, 1062 del, 4452 sub ]
%SER 85.82 [ 1803 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_16
%WER 56.65 [ 6081 / 10735, 498 ins, 1112 del, 4471 sub ]
%SER 86.24 [ 1812 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_17
%WER 56.80 [ 6098 / 10735, 478 ins, 1154 del, 4466 sub ]
%SER 86.63 [ 1820 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_7
%WER 58.83 [ 6315 / 10735, 1122 ins, 560 del, 4633 sub ]
%SER 84.96 [ 1785 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_8
%WER 57.19 [ 6139 / 10735, 990 ins, 641 del, 4508 sub ]
%SER 84.44 [ 1774 / 2101 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_9
%WER 56.00 [ 6012 / 10735, 858 ins, 687 del, 4467 sub ]
%SER 84.34 [ 1772 / 2101 ]

===== run.sh script is finished =====

